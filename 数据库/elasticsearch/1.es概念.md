## ES是什么？
https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html
Elasticsearch 是一个近实时分布式文档存储和分析引擎。

### 为什么是近实时？
https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html

位于 Elasticsearch 和磁盘之间的是文件系统缓存。内存索引缓冲区（图 1）中的文档被写入新段（图 2）。新段首先写入文件系统缓存（这很便宜），然后才刷新到磁盘（这很昂贵）。但是，在文件进入缓存后，它可以像任何其他文件一样打开和读取。
* refresh 默认1s
  更改时指定实时刷新：空字符串或true
    操作发生后立即刷新相关的主分片和副本分片（不是整个索引），以便更新的文档立即出现在搜索结果中。这只能在仔细考虑并验证它不会导致性能不佳（从索引和搜索的角度来看）之后进行。
  PUT /test/_doc/2?refresh=true
  {"test": "test"}
* 怎么保证数据没有refresh到磁盘前不会丢失？
  * translog
    es恢复索引或者重新打开索引时，它必须要先把translog里面的所有操作给恢复，所以也就是说translog越小，recovery恢复操作就越快。所以：当我们要重启节点或者关闭索引时，最好提前执行以下flush命令作为优化
  * flush
    执行flush命令之后，所有系统cache中的数据会被同步到磁盘上并且会删除旧的translog然后生成新的translog，默认情况下es的shard会每隔30分钟自动执行一次flush命令，或者当translog变大超过一定的阈值后。
### 为什么是分布式？
https://www.elastic.co/guide/en/elasticsearch/reference/current/scalability.html
可扩展性和弹性：
* 集群cluster
  * master node & data node
    master负责维护整个集群的状态，同时在node加入集群或从集群中卸载时，重写分配shard
  * 集群发现discovery机制：
    * p2p机制，集群中每个node是可以直接跟其它所有node进行通信的,几乎所有api操作都不是client和master通信的，而是和任一node通信，那个node再将请求转发给对应node来进行执行
    * master选举
* 节点node
* 分片shard
```
Elasticsearch 索引实际上只是一个或多个物理分片的逻辑分组，其中每个分片实际上是一个自包含索引。
通过将索引中的文档分布在多个分片上，并将这些分片分布在多个节点上，Elasticsearch 可以确保冗余。
这既可以防止硬件故障，又可以在将节点添加到集群时增加查询容量。
随着集群的增长（或缩小），Elasticsearch 会自动迁移分片以重新平衡集群。
分片有两种类型：主分片和副本分片。索引中的每个文档都属于一个主分片。副本分片是主分片的副本。
副本提供数据的冗余副本以防止硬件故障并增加处理读取请求（如搜索或检索文档）的容量。
索引中主分片的数量在创建索引时是固定的，但副本分片的数量可以随时更改，而不会中断索引或查询操作。
在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。

    索引在默认情况下会被分配5个主分片。我们可以设置分配3个主分片和一份副本（每个主分片拥有一个副本分片）：
    
    PUT /blogs
    {
       "settings" : {
          "number_of_shards" : 3,
          "number_of_replicas" : 1
       }
    }
    
    首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。实际上，这个过程是根据下面这个公式决定的：
    取模运算： shard = hash(routing) % number_of_primary_shards
    routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。 routing 通过 hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到 余数 。这个分布在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。
    这就解释了为什么我们要在创建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
    
    怎么解决主分片数不可变情况下的扩容呢？
    reindex : https://www.elastic.co/guide/en/elasticsearch/reference/8.0/docs-reindex.html
```
* 高可用方案
  跨集群复制 (CCR)。
### ES集群原理
p2p

## ES中的倒排序索引
```
将结果（term）作为索引key，结果对应的id数组作为索引value
如 ： 年龄 
10 [1,3,4,5,6]
8 [14,16]
12 [11,13,15]
11 [2,7,8,9,10]
13 [12]
年龄10,8,12,11,13就是一个个term
每个term对应的docIds的数据就是 posting list
对结果集进行排序[8,10,11,12,13] 就形成了 term dictionary
term dictionary太大 不能全部放入内存中 于是对term dictionay建立索引 就形成了 term index

位图 : 什么是bitset|bitmap
1. 我们的docId必须是一个数字
2. term的个数要足够的少
3. 此时我们可以用一个bit来标记某个term中存储的posting list
例子：
男 [1,3,4,5,6]
女 [2,7,8,9,10]
那么 用一个10位的bit标记term为男的posting list:
    1011110000
对应的第1,3,4,5,6被标记为1:true

一个byte就可以代表8个文档 所以100万个文档只需要12.5万个byte = 125000b = 125kb
位图极大的减少了内存使用

```

## ES中的前缀树（字典树）: 多叉树
```
又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。
它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。
```
